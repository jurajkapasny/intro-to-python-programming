{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Data Types\n",
    "In this lecture we will show how we can handle different data types in Python. Pandas will be a huge help for us during this lecture and following exercises. We will cover following topics:\n",
    "- Excel\n",
    "- JSON\n",
    "- AWS S3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the metadata [here](https://github.com/jurajkapasny/intro-to-python-programming/blob/master/data/metadata.xlsx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'data/metadata.xlsx'\n",
    "metadata = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can specify what sheet we want\n",
    "metadata_sheet1 = pd.read_excel(excel_file, sheet_name=0)\n",
    "metadata_sheet1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want second sheet\n",
    "metadata_sheet2 = pd.read_excel(excel_file, sheet_name=1)\n",
    "metadata_sheet2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sheet by name\n",
    "movies_sheet3 = pd.read_excel(excel_file, sheet_name='TAG_MAPPING')\n",
    "movies_sheet3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load excelfile object\n",
    "xlsx = pd.ExcelFile(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print available sheet names\n",
    "xlsx.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all sheets into dictionary where dict key is the sheet name and value is dataframe\n",
    "data = {} # initialize empty dict\n",
    "for sheet_name in xlsx.sheet_names:\n",
    "    data[sheet_name] = xlsx.parse(sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dict keys\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 'LOCATIONS' sheet from dictionary\n",
    "data['LOCATIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_gross = movies.sort_values(['Gross Earnings'], ascending=False)\n",
    "sorted_by_gross[['Title','Gross Earnings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_by_co_lang = (movies[['Country', 'Language', 'Gross Earnings']]\n",
    "                       .pivot_table(index=['Country', 'Language'])\n",
    "                       .unstack()\n",
    "                       .fillna(0))\n",
    "\n",
    "earnings_by_co_lang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Back to Excel\n",
    "movies.to_excel('data/all_movies.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate JSON\n",
    "import json\n",
    "\n",
    "# Creating a Python Dictionary\n",
    "data = {\"Sub_ID\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\" ],\n",
    "        \"Name\":[\"Erik\", \"Daniel\", \"Michael\", \"Sven\",\n",
    "                \"Gary\", \"Carol\",\"Lisa\", \"Elisabeth\" ],\n",
    "        \"Salary\":[\"723.3\", \"515.2\", \"621\", \"731\", \n",
    "                  \"844.15\",\"558\", \"642.8\", \"732.5\" ],\n",
    "        \"StartDate\":[ \"1/1/2011\", \"7/23/2013\", \"12/15/2011\",\n",
    "                     \"6/11/2013\", \"3/27/2011\",\"5/21/2012\", \n",
    "                     \"7/30/2013\", \"6/17/2014\"],\n",
    "        \"Department\":[ \"IT\", \"Manegement\", \"IT\", \"HR\", \n",
    "                      \"Finance\", \"IT\", \"Manegement\", \"IT\"],\n",
    "        \"Sex\":[ \"M\", \"M\", \"M\", \n",
    "              \"M\", \"M\", \"F\", \"F\", \"F\"]}\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving from python to JSON file\n",
    "import json\n",
    "\n",
    "# Parse JSON\n",
    "with open('data/data.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Parsing JSON \n",
    "with open('data/data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read JSON as a dataframe with Pandas:\n",
    "df = pd.read_json('data/data.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can store as excel/csv\n",
    "df.to_csv(\"data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Nested json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define json string\n",
    "data = [{\"state\": \"Florida\", \n",
    "        \"shortname\": \"FL\",\n",
    "        \"info\": {\"governor\": \"Rick Scott\"},\n",
    "        \"counties\": [{\"name\": \"Dade\", \"population\": 12345},\n",
    "                     {\"name\": \"Broward\", \"population\": 40000},\n",
    "                     {\"name\": \"Palm Beach\", \"population\": 60000}]},\n",
    "       {\"state\": \"Ohio\",\n",
    "        \"shortname\": \"OH\",\n",
    "        \"info\": {\"governor\": \"John Kasich\"},\n",
    "        \"counties\": [{\"name\": \"Summit\", \"population\": 1234},\n",
    "                     {\"name\": \"Cuyahoga\", \"population\": 1337}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(data=data, record_path='counties', meta=['state', 'shortname', ['info', 'governor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CUSTOM CLASS TO MANIPULATE WITH S3 DATA\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "\n",
    "\n",
    "class S3:    \n",
    "    @staticmethod\n",
    "    def get_client(credentials=None):\n",
    "        \"\"\"\n",
    "        Returns S3 client\n",
    "        \"\"\"\n",
    "        if credentials:\n",
    "            return boto3.client('s3', **credentials)\n",
    "        return boto3.client('s3')\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_bucket(bucket_name, location='eu-west-1',credentials=None):\n",
    "        \"\"\"\n",
    "        Creates bucket\n",
    "        \n",
    "        Params:\n",
    "            bucket_name (str): name of bucket\n",
    "            location (str): S3 region\n",
    "        \"\"\"\n",
    "        client = S3.get_client(credentials)\n",
    "        response = client.create_bucket(Bucket = bucket_name,\n",
    "                                        CreateBucketConfiguration={'LocationConstraint': location})\n",
    "        \n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "            raise Exception(response)\n",
    "        \n",
    "        print(f'Bucket \"{bucket_name}\" created!')\n",
    "        \n",
    "    @staticmethod\n",
    "    def delete_bucket(bucket_name, credentials=None):\n",
    "        \"\"\"\n",
    "        Delete empty (!!!) bucket\n",
    "        \n",
    "        Params:\n",
    "            bucket_name (str): name of bucket\n",
    "        \"\"\"\n",
    "        client = S3.get_client(credentials)\n",
    "        response = client.delete_bucket(Bucket=bucket_name)\n",
    "        \n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] != 204:\n",
    "            raise Exception(response)\n",
    "        \n",
    "        print(f'Bucket \"{bucket_name}\" deleted!')\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_bucket_if_not_exists(bucket_name, credentials=None):\n",
    "        \"\"\"\n",
    "        If bucket with bucket_name does not exists => creates new one\n",
    "        \"\"\"\n",
    "        available_buckets = S3.get_buckets()\n",
    "        if bucket_name not in available_buckets:\n",
    "            S3.create_bucket(bucket_name)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_buckets(with_creation_date=False, credentials=None):\n",
    "        \"\"\"\n",
    "        Returns all available buckets names \n",
    "        \n",
    "        Params:\n",
    "            with_creation_date (bool): if True => return also creation date of buckets\n",
    "            \n",
    "        Returns:\n",
    "            list with names or list with dictionaries containing buckets info\n",
    "        \"\"\"\n",
    "        client = S3.get_client(credentials)\n",
    "        response = client.list_buckets()\n",
    "        \n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "            raise Exception(response)\n",
    "        \n",
    "        if with_creation_date:\n",
    "            return response['Buckets']\n",
    "        \n",
    "        return [bucket['Name'] for bucket in response['Buckets']]\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_json_in_bucket_if_not_exists(bucket_name, file_name, initial_json=None, credentials=None):\n",
    "        \"\"\"\n",
    "        Creates json in bucket if json not exists\n",
    "        \n",
    "        Params:\n",
    "            bucket_name (str): name of bucket where to store file\n",
    "            file_name (str): path to file \n",
    "            initial_json (None or dumped json): json to store\n",
    "        \"\"\"\n",
    "        filenames = S3.get_all_objects_from_bucket(bucket_name = bucket_name, \n",
    "                                                   prefix = file_name, \n",
    "                                                   only_keys = True)\n",
    "        if file_name not in filenames:\n",
    "            if initial_json is None:\n",
    "                initial_json = json.dumps({})\n",
    "            \n",
    "            S3.store_file_in_bucket(bucket_name = bucket_name,\n",
    "                                    file_name = file_name,\n",
    "                                    file = initial_json)\n",
    "    \n",
    "    @staticmethod\n",
    "    def store_file_in_bucket(bucket_name, file_name, file, credentials=None):\n",
    "        \"\"\"\n",
    "        Stores file in bucket\n",
    "        \n",
    "        Params:\n",
    "            bucket_name (str): name of bucket where to store file\n",
    "            file_name (str): path to file\n",
    "            file (dumped json or binary): file to store\n",
    "        \"\"\"\n",
    "        client = S3.get_client(credentials)\n",
    "        response = client.put_object(Bucket = bucket_name,\n",
    "                                     Key = file_name,\n",
    "                                     Body = file)\n",
    "        \n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "            raise Exception(response)\n",
    "        \n",
    "        print(f'\"{file_name}\" succcesfully stored in \"{bucket_name}\" bucket!')\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_file_from_bucket(bucket_name, file_name, as_json=False, credentials=None):\n",
    "        \"\"\"\n",
    "        Ger file from bucket\n",
    "        \n",
    "        Params:\n",
    "            bucket_name (str): name of bucket where to store file\n",
    "            file_name (str): path to file\n",
    "            as_json (boo): if True => convert response body to json\n",
    "            \n",
    "        Returns:\n",
    "            json or bytes object\n",
    "        \"\"\"\n",
    "        client = S3.get_client(credentials)\n",
    "        response = client.get_object(Bucket = bucket_name,\n",
    "                                     Key = file_name)\n",
    "        \n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "            raise Exception(response)\n",
    "        \n",
    "        body = response['Body'].read()\n",
    "        \n",
    "        if as_json: \n",
    "            return json.loads(body) \n",
    "        \n",
    "        return io.BytesIO(body)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_all_objects_from_bucket(bucket_name, prefix='', only_keys=True, credentials=None):\n",
    "        \"\"\"\n",
    "        Get all object from bucket\n",
    "        \n",
    "        Params:\n",
    "            bucket_name (str): name of bucket where to store file\n",
    "            prefix (str): file filter\n",
    "            only_keys (bool): if True => returns only filenames\n",
    "            \n",
    "        Returns:\n",
    "            list with filenames or list with dictionaries containing files info\n",
    "        \"\"\"\n",
    "        client = S3.get_client(credentials)\n",
    "\n",
    "        kwargs = {\n",
    "            'Bucket': bucket_name,\n",
    "            'Prefix': prefix,    \n",
    "        }\n",
    "        \n",
    "        data = []\n",
    "        while True:\n",
    "            response = client.list_objects_v2(**kwargs)\n",
    "            \n",
    "            if response['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "                raise Exception(response)\n",
    "            \n",
    "            if only_keys:\n",
    "                data += [c.get('Key') for c in response.get('Contents',[])]\n",
    "            else:\n",
    "                data += response.get('Contents',[])\n",
    "\n",
    "            try:\n",
    "                kwargs['ContinuationToken'] = response['NextContinuationToken']\n",
    "            except KeyError:\n",
    "                break\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup credentials\n",
    "AWS_ACCESS_KEY_ID =  'your aws acces key id here'\n",
    "AWS_SECRET_ACCES_KEY = 'your aws secret acces key here'\n",
    "\n",
    "# credentials as dictionary\n",
    "credentials = {\n",
    "    'aws_access_key_id': AWS_ACCESS_KEY_ID,\n",
    "    'aws_secret_access_key': AWS_SECRET_ACCES_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all available buckets \n",
    "S3.get_buckets(credentials=credentials, with_creation_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all available buckets with creation dates\n",
    "S3.get_buckets(credentials=credentials, with_creation_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# transform buckets info into pandas dataframe\n",
    "df_buckets = pd.DataFrame(S3.get_buckets(credentials=credentials, with_creation_date=True))\n",
    "df_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bucket\n",
    "S3.create_bucket(credentials=credentials, bucket_name = 'spgdc-python-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete bucket\n",
    "#S3.delete_bucket(credentials=credentials, bucket_name = 'spgdc-python-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data\n",
    "test_data = [\n",
    "    {'name': 'Magnus'}, \n",
    "    {'name': 'Matus'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test_data in bucket\n",
    "S3.store_file_in_bucket(\n",
    "    credentials = credentials,\n",
    "    bucket_name='spgdc-python-training',\n",
    "    file_name='test.json',\n",
    "    file = json.dumps(test_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for objects in bucket\n",
    "S3.get_all_objects_from_bucket(\n",
    "    credentials = credentials,\n",
    "    bucket_name='spgdc-python-training',\n",
    "    prefix ='',\n",
    "    only_keys=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store multiple files in s3\n",
    "for i in range(12):\n",
    "    data = {\n",
    "        'filename': f'test_{i}.json', \n",
    "        'index': i\n",
    "    }\n",
    "    \n",
    "    S3.store_file_in_bucket(\n",
    "        credentials = credentials,\n",
    "        bucket_name='spgdc-python-training',\n",
    "        file_name=f'test_{i}.json',\n",
    "        file = json.dumps(data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for objects in bucket\n",
    "S3.get_all_objects_from_bucket(\n",
    "    credentials = credentials,\n",
    "    bucket_name='spgdc-python-training',\n",
    "    prefix ='test_1',\n",
    "    only_keys=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file from bucket\n",
    "file = S3.get_file_from_bucket(\n",
    "        credentials=credentials,\n",
    "        bucket_name='spgdc-python-training', \n",
    "        file_name='test_0.json', \n",
    "        as_json=True\n",
    "        )\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension (advanced python)\n",
    "pd.DataFrame([S3.get_file_from_bucket(credentials=credentials, bucket_name='spgdc-python-training', file_name=f'test_{i}.json', as_json=True) for i in range(12)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
